import os
from langchain_community.document_loaders import UnstructuredWordDocumentLoader, UnstructuredExcelLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Pinecone as PineconeStore
import pinecone

# ğŸ“¦ Variables de entorno (ya configuradas en Railway)
openai_api_key = os.environ["OPENAI_API_KEY"]
pinecone_api_key = os.environ["PINECONE_API_KEY"]
pinecone_env = os.environ["PINECONE_ENVIRONMENT"]
index_name = os.environ["INDEX_NAME"]

# ğŸš€ Inicializar Pinecone
pinecone.init(api_key=pinecone_api_key, environment=pinecone_env)

# ğŸ§  Crear el Ã­ndice si no existe
if index_name not in pinecone.list_indexes():
    pinecone.create_index(index_name, dimension=1536, metric="cosine")

# ğŸ“‚ Ruta donde Railway verÃ¡ los archivos (ya estÃ¡n en el repo)
base_dir = "tmp_docs"

# ğŸ“„ Lista de documentos
archivos = [
    "Manual de Cumplimiento - VIZUM.docx",
    "MetodologÃ­a PLD-FT - VIZUM.docx",
    "Matriz de Riesgos Clientes - VIZUM.xlsx",
    "MetodologÃ­a EBR - VIZUM.xlsx"
]

# ğŸ§¾ Cargar documentos
docs = []
for nombre in archivos:
    path = os.path.join(base_dir, nombre)
    print(f"ğŸ“„ Procesando {nombre}...")
    try:
        if path.endswith(".docx"):
            loader = UnstructuredWordDocumentLoader(path)
        elif path.endswith(".xlsx"):
            loader = UnstructuredExcelLoader(path)
        else:
            print(f"âŒ Tipo de archivo no soportado: {nombre}")
            continue
        docs.extend(loader.load())
        print(f"âœ… Cargado: {nombre}")
    except Exception as e:
        print(f"âŒ Error al cargar {nombre}: {e}")

print(f"ğŸ“„ Total de documentos cargados: {len(docs)}")

# âœ‚ï¸ Dividir en chunks
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)
chunks = text_splitter.split_documents(docs)
print(f"ğŸ“š Total de chunks generados: {len(chunks)}")

# ğŸ“¤ Enviar a Pinecone
print("ğŸ”— Enviando a Pinecone...")
embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
vectorstore = PineconeStore.from_documents(chunks, embeddings, index_name=index_name)
print("âœ… Documentos cargados exitosamente en Pinecone.")